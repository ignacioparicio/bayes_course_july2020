{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Course Pre-Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, import some of the libraries we will be using in the course. This will test that everything is installed correctly on your system. Running the cell below should not return errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "assert pm.__version__ == '3.9.2'\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import theano.tensor as tt\n",
    "import theano\n",
    "\n",
    "print('All packages imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything was imported, you are ready to work through the exercises below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Manipulation\n",
    "\n",
    "Loading and processing data has become easier since the development of the `pandas` library, which provides data structures and functions for automating key data operations. \n",
    "\n",
    "For importing data from most common storage formats, several `read_*` functions are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in dir(pd) if f.startswith('read_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `../data/` subdirectory includes some clinical trial data in `cdystonia.csv`. Choose the appropriate function and use it to import this data to a variable called `cdystonia`. Print the first 15 lines of the resulting `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the appropriate function to read `../data/cdystonia.csv` into a variable called `cdystonia`\n",
    "# Print the first 15 lines of the `DataFrame` `cdystonia`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is from [Statistical Methods for the Analysis of Repeated Measurements](http://www.amazon.com/Statistical-Methods-Analysis-Repeated-Measurements/dp/0387953701) by Charles S. Davis, pp. 161-163 (Springer, 2002). These data are from a multicenter, randomized controlled trial of botulinum toxin type B (BotB) in patients with cervical dystonia from nine U.S. sites.\n",
    "\n",
    "Patients were randomized to placebo (N=36), 5000 units of BotB (N=36), or 10,000 units of BotB (N=37). The response variable is the total score on Toronto Western Spasmodic Torticollis Rating Scale (TWSTRS), measuring severity, pain, and disability of cervical dystonia (high scores mean more impairment). TWSTRS was measured at baseline (week 0) and weeks 2, 4, 8, 12, 16 after treatment began, so this is a longitudinal study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Since there are repeated measures of each patient, the `patient` column alone cannot be used as an index, because it is not unique. Use some of the columns in the DataFrame to create an index for the data that is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a column in addition to \"patient\" so that the two columns have unique values, and set those two to be the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The `cdystonia` dataset is stored in **long** format, meaning that each row contains a single observation. Use pandas functions and methods to change the data to **wide** format, where each row represents the data for a single patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a wide format, where each row represents the data for a single patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. To get an idea about the efficacy of the treatment, use `pandas` to group the data by treatment group, and calculate the mean and standard deviation of the `twstrs` outcome variable for each group in week 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by treatment group, and calculate the mean and standard deviation of the `twstrs` outcome variable for each group in week 4.\n",
    "# As a sanity check, this should be the answer here:\n",
    "\n",
    "#                mean       std\n",
    "# treat\n",
    "# 10000U         34.805556  12.188565\n",
    "# 5000U          37.114286  15.311993\n",
    "# Placebo        39.342857  11.827045"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Since this is a longitudinal study, graphics are helpful for understanding the dynamics of the experiment. Using the plotting package of your choice (there are many for Python!) create a set of plots showing how the response variable changes over time for each experimental group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of plots showing how the response variable changes over time for each experimental group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Operations become much faster when we can express them as vectorized linear algebra commands. One example is generating multivariate normal distributions.\n",
    "\n",
    "Suppose we wish to generate samples with mean $\\mu$ and covariance $\\Sigma$, where $\\mu$ is $n \\times 1$ and $\\Sigma$ is $n \\times n$. One way to do this is to calculate a [*Cholesky decomposition*](https://en.wikipedia.org/wiki/Cholesky_decomposition) of $\\Sigma$, so that\n",
    "$$\n",
    "\\Sigma = LL^T.\n",
    "$$\n",
    "\n",
    "Then if $x$ is $n$ independent draws from a standard normal distribution, \n",
    "$$\n",
    "\\nu = Lx + \\mu \\sim \\mathcal{N}(\\mu, \\Sigma)\n",
    "$$\n",
    "\n",
    "### Exercises\n",
    "Let $\\mu = (3, 2)$, and\n",
    "$$\n",
    "\\Sigma = \\left(\\begin{array}{cc}\n",
    "1 & 0.9 \\\\\n",
    "0.9 & 1\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "1. Use `np.linalg.cholesky` to compute $L$, the Cholesky decomposition of $\\Sigma$\n",
    "2. In newer Python (3.6+), `@` is matrix multiplication. Confirm that $\\Sigma = LL^T$.\n",
    "3. Draw 2 independent draws from a standard normal using `x = np.random.randn(2)`, and compute $\\nu$ using `L @ x + mu`\n",
    "4. The above exercise generates 1 draw from a multivariate normal. Use `x = np.random.randn(2, 1_000)` and the same formula as above to generate 1,000 draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([[3], [2]])\n",
    "sigma = np.array([[1, 0.9], [0.9, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `np.linalg.cholesky` to compute $L$, the Cholesky decomposition of `sigma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In newer Python (3.7+), `@` is matrix multiplication. Confirm that `sigma = L @ L.T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw 2 independent draws from a standard normal using `x = np.random.randn(2)`, and compute `nu` using `L @ x + mu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above exercise generates 1 draw from a multivariate normal. Use `x = np.random.randn(2, 1_000)` and the same formula as above to generate 1,000 draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distributions and Simulation\n",
    "\n",
    "Bayesian inference relies on the use of probability distributions for constructing models. Though several statistical and machine learning packages implement their own set of probability distributions, the NumPy and SciPy libraries include general-purpose functions and classes for performing probability operations. \n",
    "\n",
    "NumPy has an efficient set of random number generators for different distributions, while SciPy implements a large set of complete probability distributions that allow them to be used in most applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import distributions as dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dists)[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a gamma distribution as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_dist = dists.gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the attributes of `gamma_dist`, we can see several important methods, including `pdf` (probability distribution function), `cdf` (cumulative distribution function), `rvs` (random number generator), and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in dir(gamma_dist) if not f.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Simulating linear regression\n",
    "\n",
    "1. Generate a (1000, 10) `features` array using a uniform distribution.\n",
    "2. Generate a (10, 1) `weights` array, using a normal distribution with standard deviation 2 and mean 0. Note this is typically unobserved.\n",
    "3. Generate a (1000, 1) `noise` array, using a normal distribution with standard deviation 1 and mean 0. Note that this is typically unobserved.\n",
    "4. Compute (1000, 1) `target` array, as `features @ weights + noise`\n",
    "5. Recover an estimate for the weights using `np.linalg.pinv(features) @ target` (`pinv` is the [Moore-Penrose pseudoinverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse))\n",
    "6. Our statistical model is \n",
    "$$\n",
    "\\text{weights} \\sim \\mathcal{N}(0, 2) \\\\\n",
    "\\text{target} | \\text{features}, \\text{weights} \\sim \\mathcal{N}(\\text{features} \\cdot \\text{weights}, 1)\n",
    "$$\n",
    "What is the log probability that all the weights are 0, and all the targets are 1, given your generated `features`?\n",
    "7. What is the log probability of your generated `weights` and generated `targets`, given your generated `features`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a (1000, 10) `features` array using a uniform distribution.\n",
    "\n",
    "# assert features.shape == (1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a (10, 1) `weights` array, using a normal distribution with standard deviation 2 and mean 0\n",
    "\n",
    "# assert weights.shape == (10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a (1000, 1) `noise` array, using a normal distribution with standard deviation 1 and mean 0\n",
    "\n",
    "# assert noise.shape == (1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute (1000, 1) `target` array, as `features @ weights + noise`\n",
    "\n",
    "# assert target.shape == (1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover an estimate for the weights using `np.linalg.pinv(features) @ target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the log probability that all the weights are 0, and all the targets are 1, given your generated `features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the log probability of your generated `weights` and `targets`, given your generated `features`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer to 5 above should match the answer `scikit-learn` provides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# LinearRegression(fit_intercept=False).fit(features, target).coef_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of running linear regression is via optimization. Suppose we want to minimize the sum of squares using scipy. We can do this using `scipy.optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_bfgs\n",
    "\n",
    "features = np.random.uniform(size=(1000, 10))\n",
    "weights = np.random.normal(0, 2, size=(10, 1))\n",
    "noise = np.random.normal(0, 1, size=(1000, 1))\n",
    "target = (features @ weights + noise).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Find the weights with the least mean squared error using `fmin_bfgs`. It expects a function to minimize and an initial point.\n",
    "\n",
    "1. The function to minimize should accept an argument `x`, and return `((features @ x - target) ** 2).mean()`\n",
    "2. You can initialize with a vector of 10 zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the function to minimize, and an initial point\n",
    "\n",
    "def loss_function(x):\n",
    "    pass\n",
    "\n",
    "# initial_point = \n",
    "\n",
    "# assert initial_point.shape == (10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_x = fmin_bfgs(loss_function, initial_point)\n",
    "# min_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This answer should match our solution using linear algebra, or using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.pinv(features) @ target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LinearRegression(fit_intercept=False).fit(features, target).coef_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano\n",
    "\n",
    "Our primary tool for building Bayesian models in this course is PyMC3, which relies on a third-party computational backend called Theano for much of the heavy-lifting. Theano was created to perform deep learning, but PyMC3 uses some of its key features to implement modern sampling-based fitting methods. This section is a short introduction to Theano to give you a little practice with some of its data structures and functions before we jump in and use PyMC3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing operations on data structures\n",
    "\n",
    "To get us started with Theano and get a feel of what we're working with, \n",
    "let's make a simple function: multiply a scalar with a matrix, and add that to another matrix. Here is how you do\n",
    "it:\n",
    "\n",
    "#### Step 1 - Declaring Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from theano import function, shared\n",
    "import theano.tensor as tt\n",
    "import theano\n",
    "\n",
    "c = tt.dscalar('c')\n",
    "x = tt.dmatrix('x')\n",
    "y = tt.dmatrix('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Theano, all symbols must be typed. In particular, `tt.dscalar`\n",
    "is the type we assign to \"0-dimensional arrays (`scalar`) of doubles\n",
    "(`d`). It is a Theano `type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dmatrix`` is the Type for matrices of doubles. Then we can use\n",
    "our new function on 2D arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.dscalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have created objects of the type `TensorVariable`. A **tensor** is a generalization of an array to (potentially) multiple dimensions. Thus, everything from a scalar to a 5-dimensional hyper-matrix can be accomodated with the same abstraction. All expressions defined in Theano are performed by associating tensors with operations and with one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Symbolic Expressions\n",
    "\n",
    "The second step is to multiply `c` with `x`, then add `y`, yielding another variable `z`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = c*x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `pp` function to *pretty-print* out the computation associated to *z*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.printing import pp\n",
    "print(pp(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Compiling a Function\n",
    "\n",
    "The last step is to create a function taking `c`, `x` and `y` as inputs\n",
    "and giving `z` as output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = function([c, x, y], z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument to `function()` is a list of Variables\n",
    "that will be provided as inputs to the function. The second argument\n",
    "is a single Variable *or* a list of Variables. For either case, the second\n",
    "argument is what we want to see as output when we apply the function. *f* may\n",
    "then be used like a normal Python function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 2\n",
    "X = [[1, 2], [3, 4]]\n",
    "Y = [[10, 20], [30, 40]]\n",
    "\n",
    "f(C, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are following along and typing into an interpreter, you may have\n",
    "noticed that there was a slight delay in executing the ``function``\n",
    "instruction. Behind the scenes, *f* was being **compiled into C code**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, Theano builds a graph structure composed of interconnected `Variable` nodes, `op` nodes and `apply` nodes. \n",
    "\n",
    "An `op` node encapsulates a particular mathematical operation, such as an arithmetic operation or a transformation.\n",
    "\n",
    "An `apply` node represents the application of an `op` to some variables. It is important to draw the difference between the definition of a computation represented by an `op` and its application to some actual data which is represented by the apply node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(theano.printing.pydotprint(f, return_image=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Variable` is the main data structure you work with when\n",
    "using Theano. By calling `tt.dscalar` or `tt.dmatrix` with a string argument, you create a\n",
    "`Variable` representing a floating-point scalar or matrix quantity with the\n",
    "given name. If you provide no argument, the symbol will be unnamed. Names\n",
    "are not required, but they can help debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's create a (slightly) more interesting function: a logistic curve. The logistic transformation is:\n",
    "\n",
    "$$\\log\\left[\\frac{p}{1-p}\\right] = x$$\n",
    "\n",
    "Which transforms values on the $[0, 1]$i interval to the real line. Most often, we are doing the inverse of this, for example, when we build a logistic regression. The inverse of this function is:\n",
    "\n",
    "$$p = \\frac{1}{1 + \\exp(-x)}$$\n",
    "\n",
    "Implement this function in Theano, compile it, and run it on one of the matrices created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: most of Theano's functions are in the theano.tensor submodule."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
